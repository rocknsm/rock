#######################################################
###################  Kubernetes Install ###############
#######################################################
---

#- name: Verify Docker is present
#  yum:
#    name: docker
#    state: present

- name: Copy sysctl config file
  copy:
    src: files/k8s.conf
    dest: /etc/sysctl.d/k8s.conf
    owner: root
    group: root
    mode: 0644

- name: Disable SELinux
  selinux:
    state: disabled
  register: selinux

- name: Reboot to finish off SELinux completely
  command: "/sbin/shutdown -r +1 --no-wall"
  async: 0
  poll: 0
  when: selinux.changed
  ignore_errors: yes

- name: Wait for boot
  wait_for:
    host: "{{ inventory_hostname }}"
    port: 22
    delay: 300
  delegate_to: localhost
  when: selinux.changed

- name: Swap Off
  command: swapoff --all

- name: 'Remove swap'
  mount:
    path: swap
    state: absent

- name: 'Pass bridged IPv4 traffic to iptables'
  sysctl:
    name: net.bridge.bridge-nf-call-iptables
    sysctl_set: yes
    reload: yes
    value: 1
    state: present

- name: "Setup Kubernetes repo"
  yum_repository:
    baseurl: "{{ kubernetes_baseurl }}"
    description: "Kubernetes YUM repo"
    gpgcheck: true
    gpgkey: "{{ kubernetes_gpgurl }}"
    name: kubernetes

- name: 'Install Kubernetes packages'
  yum:
    name: "{{ item }}"
    state: 'installed'
  with_items:
    - "kubeadm"
    - "kubelet"
    - "kubectl"
  register: installed_packages

- name: Reset Kubernetes Cluster
  command: kubeadm reset
  register: debug_output
  when: installed_packages is defined and not installed_packages.changed

- name: Remove Kubernetes Packages to clear cache
  yum:
    name: "{{ item }}"
    state: absent
  with_items:
    - kubeadm
    - kubelet
    - kubectl
  when: installed_packages is defined and not installed_packages.changed

- name: Stop Services
  systemd:
    name: docker
    state: stopped

- name: Remove Artifacts
  file:
    path: "{{ item }}"
    state: absent
  with_items:
    - /var/lib/cni
    - /var/lib/kubelet
    - /etc/cni
  when: installed_packages is defined and not installed_packages.changed

- name: Remove Interfaces
  shell: |
    if [ $(ifconfig | grep {{ item }} | wc -l ) -gt 0 ]; then
      ip link delete {{ item }};
    fi
  with_items:
    - flannel.1
    - cni0

- name: Reinstall Kubernetes Packages
  yum:
    name: "{{ item }}"
    state: present
  with_items:
    - kubeadm
    - kubelet
    - kubectl
  when: installed_packages is defined and not installed_packages.changed

- name: 'Start Services'
  systemd:
    name: "{{ item }}"
    state: 'started'
    daemon_reload: yes
    enabled: 'yes'
  with_items:
    - docker
    - kubelet

- name: Install Cockpit for Kubernetes
  yum:
    name: cockpit-kubernetes
    state: installed

- name: "Create Kubernetes config directory"
  file:
    path: "{{ item }}"
    mode: u+rw,g+rw
    owner: root
    group: root
    state: directory
  when: inventory_hostname in groups['master-servers']
  with_items:
    - "{{ kube_dir }}"
    - "{{ kube_config_dir }}"

- name: 'Install templates'
  template:
    src: "{{ item }}.yml.j2"
    dest: "{{ kube_dir }}/{{ item }}.yml"
    owner: root
    group: root
    mode: 0644
  with_items:
    - metallb
    - kubeadm
    - kube-flannel
    - dashboard
    - vars
  when: inventory_hostname in groups['master-servers']

- name: 'Disable Firewalld service'
  systemd:
    name: firewalld
    enabled: no
    state: stopped

- name: 'Init Kubernetes cluster'
  #shell: "kubeadm init --config {{ kube_dir }}/kubeadm.yml | grep 'kubeadm join --token'"
  shell: "kubeadm init --pod-network-cidr=10.244.0.0/16 | grep 'kubeadm join --token' | tee /etc/kubernetes/join-node.sh"
  register: kube_join_cluster_cmd
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ kube_join_cluster_cmd.cmd }}"
      - "Stdout is: {{ kube_join_cluster_cmd.stdout }}"
  when: debug_enabled is defined and debug_enabled and kube_join_cluster_cmd.stdout is defined

- name: 'Configure Kubelet'
  lineinfile:
    path: /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
    regexp: '^Environment="KUBELET_EXTRA_ARGS='
    line: 'Environment="KUBELET_EXTRA_ARGS=--runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice"'
    insertbefore: '^ExecStart=$'

- name: 'Restart Kubelet service'
  systemd:
    name: kubelet
    enabled: yes
    daemon_reload: yes
    state: restarted

- name: Create credential directory
  file:
    path: "~/.kube"
    state: directory
    mode: u+rw,g+rw

- name: Retrieve generated credentials
  fetch:
    src: "{{ kubernetes_conf_file }}"
    dest: files/config
    flat: yes
  when: "inventory_hostname in groups['master-servers']"

- name: Propagate cluster admin credentials
  copy:
    src: files/config
    dest: ~/.kube/config
    mode: 0644

- name: 'Install pod network: kube-router'
#  shell: |
#    export kubever=$(kubectl version | base64 | tr -d '\n')
#    kubectl apply -f https://cloud.weave.works/k8s/net?k8s-version=$kubever
#  command: "kubectl apply -f {{ kube_dir }}/calico.yml"
  command: "kubectl apply -f {{ kube_dir }}/kube-flannel.yml"
#  command: "kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml"
#  shell: |
#    kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter-all-features.yaml
#    kubectl -n kube-system delete ds kube-proxy
#    docker run --privileged --net=host gcr.io/google_containers/kube-proxy-amd64:v1.7.3 kube-proxy --cleanup-iptables
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: Wait for Master Node to be ready
  shell: "NODES_READY=0; while [ $NODES_READY -lt 1 ]; do NODES_READY=1; for stat in $(kubectl get nodes | grep -v NAME | awk '{ print $2 }'); do if [ $stat != 'Ready' ]; then NODES_READY=0; echo -n .; sleep 1; fi done; done;"
  register: debug_output
  when: "inventory_hostname in groups['master-servers']"

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

# By default the cluster will not scehdule pods on the master for security reasons.
# The below task removes that restriction.
- name: 'Remove master taint from master'
  command: 'kubectl taint nodes --all node-role.kubernetes.io/master-'
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: 'Install MetalLB LoadBalancer'
  command: 'kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.3.1/manifests/metallb.yaml'
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: 'Apply MetalLB Config'
  command: 'kubectl apply -f {{ kube_dir }}/metallb.yml'
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: Wait for system pods to be ready
  shell: "PODS_READY=0; while [ $PODS_READY -lt 1 ]; do PODS_READY=1; for stat in $(kubectl get pods -n kube-system | grep -v NAME | awk '{ print $3 }' | cut -d'/' -f 1); do if [ $stat == '0' ]; then PODS_READY=0; echo -n .; sleep 1; fi done; done;"
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: 'Join Kubernetes cluster'
  command: "{{ hostvars[item].kube_join_cluster_cmd.stdout }}"
  register: debug_output
  when: "inventory_hostname in groups['nodes']"
  with_items: "{{ groups['master-servers'] }}"

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

# When this stalled for me I had to go into the node, run the join command from
# init. It then had a bunch of errors I:
# 1. Deleted all the files it mentioned
# 2. Ran 'systemctl stop kubelet'
# 3. Re-ran the join command
# That cleared up this problem for me
- name: Wait for Nodes to Register
  shell: "while [ $(kubectl get nodes | wc -l) -lt {{ groups['nodes'] | length + 1}} ]; do echo -n .; done;"
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: Wait for Nodes to be ready
  shell: "NODES_READY=0; while [ $NODES_READY -lt 1 ]; do NODES_READY=1; for stat in $(kubectl get nodes | grep -v NAME | awk '{ print $2 }'); do if [ $stat != 'Ready' ]; then NODES_READY=0; echo -n .; sleep 1; fi done; done;"
  register: debug_output
  when: "inventory_hostname in groups['master-servers']"

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: Restart Cockpit
  systemd:
    name: cockpit
    state: restarted

- name: 'Label masters'
  command: 'kubectl label nodes {{ item }} role=server'
  with_items: "{{ groups['master-servers'] }}"
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: 'Label sensors'
  command: 'kubectl label nodes {{ item }} role=sensor'
  with_items: "{{ groups['sensors'] }}"
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: 'Label secondary servers'
  command: 'kubectl label nodes {{ item }} role=server'
  with_items: "{{ groups['servers'] }}"
  register: debug_output
  when: inventory_hostname in groups['master-servers']

- name: Debug Output
  debug:
    msg:
      - "Command is: {{ debug_output.cmd }}"
      - "Stdout is: {{ debug_output.stdout }}"
  when: debug_enabled is defined and debug_enabled and debug_output.stdout is defined

- name: Wait for kube-dns to come up
  shell: |
    while [ $(kubectl -n kube-system get pods | grep kube-dns | awk '{print $2}' | awk -F '/' '{ if($1 == $2) print 1; else print 0;}') -eq 0 ]; do
      echo -n .;
      sleep 1;
    done;
  when: inventory_hostname in groups['master-servers']

- name: Get kube-dns IP
  shell: "kubectl get svc -n kube-system | grep kube-dns | awk '{print $3}'"
  register: kube_dns_ip

- name: Insert kube-dns into /etc/resolv.conf
  lineinfile:
    insertbefore: BOF
    line: "nameserver {{ kube_dns_ip.stdout }}"
    path: /etc/resolv.conf
  when: inventory_hostname not in groups['master-servers']

- name: Install Dashboard
  command: "kubectl apply -f {{ kube_dir }}/dashboard.yml"
  when: inventory_hostname in groups['master-servers']

- name: Add Var configmap
  command: "kubectl create configmap vars --from-file=v{{ kube_dir }}/vars.yml"

...
